{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88399f04-1fed-4c70-9267-27e5e1336925",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f758bf55-fb2b-4434-9589-58b1ab30ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We don't need to install nltk, it should come with anaconda, but nltk\n",
    "# # does need to download some data.\n",
    "# !python -c \"import nltk; nltk.download('stopwords')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e95035da-ea37-4e8f-8b61-2267e932ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3116ded7-5503-4b1c-977d-6638ff0721db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7821f127-1afc-421b-954b-f674913508de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antfin transfers 10.3% stake to Paytm chief Vi...</td>\n",
       "      <td>Antfin (Netherlands) Holding BV has transferre...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nepal asks India for rice, sugar to avert poss...</td>\n",
       "      <td>Nepal government has requested India to facili...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GQG Partners buys 8.1% stake in Adani Power fo...</td>\n",
       "      <td>Investment firm GQG Partners bought an 8.1% st...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USDA cuts rice trade forecast for 2023, 2024 p...</td>\n",
       "      <td>US Department of Agriculture (USDA) lowered th...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hyundai to buy General Motors' Talegaon plant ...</td>\n",
       "      <td>Hyundai Motor India signed an asset purchase a...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Antfin transfers 10.3% stake to Paytm chief Vi...   \n",
       "1  Nepal asks India for rice, sugar to avert poss...   \n",
       "2  GQG Partners buys 8.1% stake in Adani Power fo...   \n",
       "3  USDA cuts rice trade forecast for 2023, 2024 p...   \n",
       "4  Hyundai to buy General Motors' Talegaon plant ...   \n",
       "\n",
       "                                             content  category  \n",
       "0  Antfin (Netherlands) Holding BV has transferre...  business  \n",
       "1  Nepal government has requested India to facili...  business  \n",
       "2  Investment firm GQG Partners bought an 8.1% st...  business  \n",
       "3  US Department of Agriculture (USDA) lowered th...  business  \n",
       "4  Hyundai Motor India signed an asset purchase a...  business  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = acquire.get_news_articles()\n",
    "article.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877d3567-67f4-4d70-848b-26692c8852b6",
   "metadata": {},
   "source": [
    "**Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:**\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5e94699-bb09-42ec-b442-fa64084a3713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string_:list):\n",
    "    clean_df = []\n",
    "    for ele in string_.values:\n",
    "        # Lowercase everything in the first row\n",
    "        lower_str= ele.lower()\n",
    "        # Normalize unicode characters\n",
    "        norm_string = unicodedata.normalize(\"NFKD\", lower_str).encode('ascii', \"ignore\").decode('utf-8', 'ignore')\n",
    "        # Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "        clean_df.append(re.sub(r\"[^a-z0-9'\\s]\", \"\", norm_string))\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f82c0c4f-c99c-486d-9622-8efafed49c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_str = basic_clean(article.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b372b-703a-4bab-9ed4-506876bd9ebf",
   "metadata": {},
   "source": [
    "**Define a function named tokenize. It should take in a string and tokenize all the words in the string.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1341170e-0638-43ff-bed5-41ac3a527036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string_:list):\n",
    "    tokenized_lst = []\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    for ele in string_:\n",
    "        tokenized_lst.append(tokenizer.tokenize(ele, return_str=True))\n",
    "    return tokenized_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53507629-926d-4770-9b76-696b42704e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_str = tokenize(normalized_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c380c8-f23c-4efe-95e2-670c8732f502",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Define a function named stem. It should accept some text and return the text after applying stemming to all the words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5532d33-f08e-4357-98e1-388352756ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string_:list):\n",
    "    # Create the nltk stemmer object, then use it\n",
    "    article_stemmed_lst = []\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    for parag in string_:\n",
    "        stems = [ps.stem(ele) for ele in parag.split()]\n",
    "        article_stemmed = \" \".join(stems)\n",
    "        article_stemmed_lst.append(article_stemmed)\n",
    "    \n",
    "    return article_stemmed_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12bea15d-e401-423e-818b-6abe31647207",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_str = stem(tokenized_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149615b3-38c9-4184-bb91-66bce26ebc16",
   "metadata": {},
   "source": [
    "**Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6c8e5ab-070f-4676-913a-04918f20bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string_:list):\n",
    "    # Create the nltk stemmer object, then use it\n",
    "    article_lemmatize_lst = []\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    for parag in string_:\n",
    "        lemma = [wnl.lemmatize(ele) for ele in parag.split()]\n",
    "        article_lemmatize = \" \".join(lemma)\n",
    "        article_lemmatize_lst.append(article_lemmatize)\n",
    "    \n",
    "    return article_lemmatize_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a01a36d6-b829-441d-a75b-ac81065c78f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_str = lemmatize(tokenized_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa124127-9b17-43c4-8ce9-b0d23084e508",
   "metadata": {},
   "source": [
    "**Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.**\n",
    "\n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b865687c-df2b-47d7-b639-cfa280bb4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string_:list, extra_words=\"\", exclude_words=None):\n",
    "    article_without_stopwords = []\n",
    "    # extra_words_lst = []\n",
    "    for words in string_:\n",
    "        stopword_list = stopwords.words('english') + extra_words\n",
    "        exclude_words = [w for w in words.split() if w not in stopword_list]\n",
    "\n",
    "        article_without_stopwords.append(' '.join(exclude_words))\n",
    "    return article_without_stopwords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "832fb18c-d05b-4fb2-8f21-6a9e80fcf8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_sp_wds = remove_stopwords(lemmatized_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc4645f-5926-4c6a-8158-bc66132ff743",
   "metadata": {},
   "source": [
    "**Make another dataframe for the Codeup blog posts. Name the dataframe cod**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "526014cd-9a02-4333-a4dd-cc5350c10b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antfin transfers 10.3% stake to Paytm chief Vi...</td>\n",
       "      <td>Antfin (Netherlands) Holding BV has transferre...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nepal asks India for rice, sugar to avert poss...</td>\n",
       "      <td>Nepal government has requested India to facili...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GQG Partners buys 8.1% stake in Adani Power fo...</td>\n",
       "      <td>Investment firm GQG Partners bought an 8.1% st...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USDA cuts rice trade forecast for 2023, 2024 p...</td>\n",
       "      <td>US Department of Agriculture (USDA) lowered th...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hyundai to buy General Motors' Talegaon plant ...</td>\n",
       "      <td>Hyundai Motor India signed an asset purchase a...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Antfin transfers 10.3% stake to Paytm chief Vi...   \n",
       "1  Nepal asks India for rice, sugar to avert poss...   \n",
       "2  GQG Partners buys 8.1% stake in Adani Power fo...   \n",
       "3  USDA cuts rice trade forecast for 2023, 2024 p...   \n",
       "4  Hyundai to buy General Motors' Talegaon plant ...   \n",
       "\n",
       "                                             content  category  \n",
       "0  Antfin (Netherlands) Holding BV has transferre...  business  \n",
       "1  Nepal government has requested India to facili...  business  \n",
       "2  Investment firm GQG Partners bought an 8.1% st...  business  \n",
       "3  US Department of Agriculture (USDA) lowered th...  business  \n",
       "4  Hyundai Motor India signed an asset purchase a...  business  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = acquire.get_news_articles()\n",
    "article.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddef2a46-6705-42fd-9784-2d0e9682dfe0",
   "metadata": {},
   "source": [
    "**For each dataframe, produce the following columns:**\n",
    "\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a88363c7-b466-4525-8393-70d1d5d29035",
   "metadata": {},
   "outputs": [],
   "source": [
    "article[\"clean_normalized\"] = np.array(basic_clean(article.content))\n",
    "article[\"stemmed\"] = np.array(stem(tokenized_str))\n",
    "article[\"lemmatized\"] = np.array(lemmatize(tokenized_str))\n",
    "article[\"with_out_stop_words\"] = np.array(remove_stopwords(lemmatized_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cf934ee-9ae9-43f7-8b12-95146254e949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_normalized</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>with_out_stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antfin transfers 10.3% stake to Paytm chief Vi...</td>\n",
       "      <td>Antfin (Netherlands) Holding BV has transferre...</td>\n",
       "      <td>business</td>\n",
       "      <td>antfin netherlands holding bv has transferred ...</td>\n",
       "      <td>antfin netherland hold bv ha transfer it 103 s...</td>\n",
       "      <td>antfin netherlands holding bv ha transferred i...</td>\n",
       "      <td>antfin netherlands holding bv ha transferred 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nepal asks India for rice, sugar to avert poss...</td>\n",
       "      <td>Nepal government has requested India to facili...</td>\n",
       "      <td>business</td>\n",
       "      <td>nepal government has requested india to facili...</td>\n",
       "      <td>nepal govern ha request india to facilit the s...</td>\n",
       "      <td>nepal government ha requested india to facilit...</td>\n",
       "      <td>nepal government ha requested india facilitate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GQG Partners buys 8.1% stake in Adani Power fo...</td>\n",
       "      <td>Investment firm GQG Partners bought an 8.1% st...</td>\n",
       "      <td>business</td>\n",
       "      <td>investment firm gqg partners bought an 81 stak...</td>\n",
       "      <td>invest firm gqg partner bought an 81 stake in ...</td>\n",
       "      <td>investment firm gqg partner bought an 81 stake...</td>\n",
       "      <td>investment firm gqg partner bought 81 stake ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USDA cuts rice trade forecast for 2023, 2024 p...</td>\n",
       "      <td>US Department of Agriculture (USDA) lowered th...</td>\n",
       "      <td>business</td>\n",
       "      <td>us department of agriculture usda lowered the ...</td>\n",
       "      <td>us depart of agricultur usda lower the global ...</td>\n",
       "      <td>u department of agriculture usda lowered the g...</td>\n",
       "      <td>u department agriculture usda lowered global r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hyundai to buy General Motors' Talegaon plant ...</td>\n",
       "      <td>Hyundai Motor India signed an asset purchase a...</td>\n",
       "      <td>business</td>\n",
       "      <td>hyundai motor india signed an asset purchase a...</td>\n",
       "      <td>hyundai motor india sign an asset purchas agre...</td>\n",
       "      <td>hyundai motor india signed an asset purchase a...</td>\n",
       "      <td>hyundai motor india signed asset purchase agre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Antfin transfers 10.3% stake to Paytm chief Vi...   \n",
       "1  Nepal asks India for rice, sugar to avert poss...   \n",
       "2  GQG Partners buys 8.1% stake in Adani Power fo...   \n",
       "3  USDA cuts rice trade forecast for 2023, 2024 p...   \n",
       "4  Hyundai to buy General Motors' Talegaon plant ...   \n",
       "\n",
       "                                             content  category  \\\n",
       "0  Antfin (Netherlands) Holding BV has transferre...  business   \n",
       "1  Nepal government has requested India to facili...  business   \n",
       "2  Investment firm GQG Partners bought an 8.1% st...  business   \n",
       "3  US Department of Agriculture (USDA) lowered th...  business   \n",
       "4  Hyundai Motor India signed an asset purchase a...  business   \n",
       "\n",
       "                                    clean_normalized  \\\n",
       "0  antfin netherlands holding bv has transferred ...   \n",
       "1  nepal government has requested india to facili...   \n",
       "2  investment firm gqg partners bought an 81 stak...   \n",
       "3  us department of agriculture usda lowered the ...   \n",
       "4  hyundai motor india signed an asset purchase a...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  antfin netherland hold bv ha transfer it 103 s...   \n",
       "1  nepal govern ha request india to facilit the s...   \n",
       "2  invest firm gqg partner bought an 81 stake in ...   \n",
       "3  us depart of agricultur usda lower the global ...   \n",
       "4  hyundai motor india sign an asset purchas agre...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  antfin netherlands holding bv ha transferred i...   \n",
       "1  nepal government ha requested india to facilit...   \n",
       "2  investment firm gqg partner bought an 81 stake...   \n",
       "3  u department of agriculture usda lowered the g...   \n",
       "4  hyundai motor india signed an asset purchase a...   \n",
       "\n",
       "                                 with_out_stop_words  \n",
       "0  antfin netherlands holding bv ha transferred 1...  \n",
       "1  nepal government ha requested india facilitate...  \n",
       "2  investment firm gqg partner bought 81 stake ad...  \n",
       "3  u department agriculture usda lowered global r...  \n",
       "4  hyundai motor india signed asset purchase agre...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
