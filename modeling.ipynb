{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc7a79f-967f-4c71-9089-96a1c84d0523",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca942ae-9117-4b1d-b151-c74766855ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import acquire #basic_clean, lemmatize\n",
    "import prepare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b790c38a-ec87-4a70-a0a3-5aed2bb1fa1c",
   "metadata": {},
   "source": [
    "**Get and prep data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f4ff015-df4a-4cfc-9f0c-d1a3c817bf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antfin transfers 10.3% stake to Paytm chief Vi...</td>\n",
       "      <td>Antfin (Netherlands) Holding BV has transferre...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nepal asks India for rice, sugar to avert poss...</td>\n",
       "      <td>Nepal government has requested India to facili...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GQG Partners buys 8.1% stake in Adani Power fo...</td>\n",
       "      <td>Investment firm GQG Partners bought an 8.1% st...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USDA cuts rice trade forecast for 2023, 2024 p...</td>\n",
       "      <td>US Department of Agriculture (USDA) lowered th...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hyundai to buy General Motors' Talegaon plant ...</td>\n",
       "      <td>Hyundai Motor India signed an asset purchase a...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Antfin transfers 10.3% stake to Paytm chief Vi...   \n",
       "1  Nepal asks India for rice, sugar to avert poss...   \n",
       "2  GQG Partners buys 8.1% stake in Adani Power fo...   \n",
       "3  USDA cuts rice trade forecast for 2023, 2024 p...   \n",
       "4  Hyundai to buy General Motors' Talegaon plant ...   \n",
       "\n",
       "                                             content  category  \n",
       "0  Antfin (Netherlands) Holding BV has transferre...  business  \n",
       "1  Nepal government has requested India to facili...  business  \n",
       "2  Investment firm GQG Partners bought an 8.1% st...  business  \n",
       "3  US Department of Agriculture (USDA) lowered th...  business  \n",
       "4  Hyundai Motor India signed an asset purchase a...  business  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = acquire.get_news_articles()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0609b8b8-0c97-4141-9203-44e6c0d0ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \" \".join(df.content)\n",
    "# clean up the text\n",
    "document = re.sub(r\"[^a-z0-9'\\s]\", \"\", document)\n",
    "# transform into a series\n",
    "words = pd.Series(document.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9a498a3-b9c0-4f2f-b367-e7b5615d002b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             ntfin\n",
       "1        etherlands\n",
       "2            olding\n",
       "3               has\n",
       "4       transferred\n",
       "           ...     \n",
       "2303          three\n",
       "2304         months\n",
       "2305             of\n",
       "2306            the\n",
       "2307           year\n",
       "Length: 2308, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98965bfc-66b7-46b3-9f5b-f2945f3559b1",
   "metadata": {},
   "source": [
    "## Feature Extraction: TF-IDF\n",
    "\n",
    "- TF: Term Frequency; how often a word appears in a document.\n",
    "- IDF: Inverse Documnet Frequency; a measure based on in how many documents will a word appear.\n",
    "- TF-IDF: A combination of the two measures above.\n",
    "\n",
    "## Term Frequency (TF)\n",
    "\n",
    "Term frequency can be calculated in a number of ways, all of which reflect how frequently a word appears in a document.\n",
    "\n",
    "- Raw Count: This is simply the count of the number of occurances of each word.\n",
    "- Frequency: The number of times each word appears divided by the total number of words.\n",
    "- Augmented Frequency: The frequency of each word divided by the maximum frequency. This can help prevent bias towards larger documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2adb6521-d7fb-4fd9-9f01-d0d5491b34b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to</td>\n",
       "      <td>80</td>\n",
       "      <td>0.034662</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>64</td>\n",
       "      <td>0.027730</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>60</td>\n",
       "      <td>0.025997</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>56</td>\n",
       "      <td>0.024263</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>52</td>\n",
       "      <td>0.022530</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  raw_count  frequency  augmented_frequency\n",
       "0   to         80   0.034662                 1.00\n",
       "1   of         64   0.027730                 0.80\n",
       "2  the         60   0.025997                 0.75\n",
       "3   in         56   0.024263                 0.70\n",
       "4  and         52   0.022530                 0.65"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the count of the number of occurances of each word.\n",
    "word_df = pd.DataFrame(words.value_counts().index, columns=[\"word\"]).assign(raw_count= words.value_counts().values)\n",
    "# The number of times each word appears divided by the total number of words.\n",
    "frequency = word_df.raw_count / len(words)\n",
    "# The frequency of each word divided by the maximum frequency. \n",
    "augmented_frequency = frequency / frequency.max()\n",
    "# add to the dataframe\n",
    "word_df[\"frequency\"] = frequency\n",
    "word_df[\"augmented_frequency\"] = augmented_frequency\n",
    "word_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cbd065-07a8-4b03-a8f8-44c9a60081b8",
   "metadata": {},
   "source": [
    "## Inverse Document Frequency (IDF) (must have multiple ducuments)\n",
    "\n",
    "- A higher IDF means that a word provides more information. That is, it is more relevant within a single document.\n",
    "\n",
    "Inverse Document Frequency tells us how much information a word provides. It is based on how commonly a word appears across multiple documents. The metric is divised such that the more frequently a word appears, the lower the IDF for that word will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fde35d6-1505-4a1e-8abb-a75203cbe879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13,), (13,), (14,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Create my own documents from the article dataframe\n",
    "document1 = df.content[:len(df.content)//3]\n",
    "document2 = df.content[len(document1):len(document1)*2]\n",
    "document3 = df.content[len(document1)*2:]\n",
    "document1.shape,document2.shape,document3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39ab6483-fc11-46ea-8c9f-2b3ffcc9a1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Antfin (Netherlands) Holding BV has transferre...\n",
       "1     Nepal government has requested India to facili...\n",
       "2     Investment firm GQG Partners bought an 8.1% st...\n",
       "3     US Department of Agriculture (USDA) lowered th...\n",
       "4     Hyundai Motor India signed an asset purchase a...\n",
       "5     Combined remuneration for the heads of the Nif...\n",
       "6     H&M is investigating 20 alleged instances of l...\n",
       "7     A glitch in Bank of Ireland's app allowed cust...\n",
       "8     Union Cabinet approved a ₹32,500-crore budget ...\n",
       "9     The Dutch economy has entered a recession as i...\n",
       "10    Antfin (Netherlands) Holding BV has transferre...\n",
       "11    Nepal government has requested India to facili...\n",
       "12    Investment firm GQG Partners bought an 8.1% st...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e295f2a-ed51-42f3-bbfc-7a2ce2f4b8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and lemmatizing...\n",
      "\n",
      "Cleaning and lemmatizing...\n",
      "\n",
      "Cleaning and lemmatizing...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# our 3 example documents\n",
    "documents = {\n",
    "    'document1': \" \".join(document1),\n",
    "    'document2': \" \".join(document2),\n",
    "    'document3': \" \".join(document3)\n",
    "}\n",
    "\n",
    "for doc, topic in documents.items():\n",
    "    # clean and lemmatize the data and join them back by space\n",
    "    documents[doc] = \" \".join(prepare.prep_data(topic))\n",
    "    print('Cleaning and lemmatizing...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56e899ae-c3fe-4891-84c4-3505f017d4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antfin</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>february</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tracked</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          idf\n",
       "word         \n",
       "antfin    2.0\n",
       "february  2.0\n",
       "case      2.0\n",
       "156       2.0\n",
       "tracked   2.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple way to calculate idf for demonstration. Note that this\n",
    "# function relies on the globally defined documents variable.\n",
    "def idf(word):            \n",
    "    n_occurences = sum([1 for doc in documents.values() if word in doc])\n",
    "    return len(documents) / n_occurences + 1\n",
    "\n",
    "# Get a list of the unique words\n",
    "unique_words = pd.Series(' '.join(documents.values()).split()).unique()\n",
    "\n",
    "# put the unique words into a data frame\n",
    "(pd.DataFrame(dict(word=unique_words))\n",
    " # calculate the idf for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # sort the data for presentation purposes\n",
    " .set_index('word')\n",
    " .sort_values(by='idf', ascending=False)\n",
    " .head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e34635-a271-44ab-b3b7-20d26493ec79",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7afaaaa0-b430-4632-8832-2984ce0b3860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>doc</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>india</td>\n",
       "      <td>document2</td>\n",
       "      <td>0.079734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tonne</td>\n",
       "      <td>document2</td>\n",
       "      <td>0.059801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tonne</td>\n",
       "      <td>document1</td>\n",
       "      <td>0.059801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>india</td>\n",
       "      <td>document1</td>\n",
       "      <td>0.059801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crore</td>\n",
       "      <td>document2</td>\n",
       "      <td>0.053156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>mitigate</td>\n",
       "      <td>document2</td>\n",
       "      <td>0.006645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>possible</td>\n",
       "      <td>document2</td>\n",
       "      <td>0.006645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>food</td>\n",
       "      <td>document2</td>\n",
       "      <td>0.006645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>scarcity</td>\n",
       "      <td>document2</td>\n",
       "      <td>0.006645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>report</td>\n",
       "      <td>document3</td>\n",
       "      <td>0.006645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>903 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word        doc    tf_idf\n",
       "0       india  document2  0.079734\n",
       "1       tonne  document2  0.059801\n",
       "1       tonne  document1  0.059801\n",
       "0       india  document1  0.059801\n",
       "2       crore  document2  0.053156\n",
       "..        ...        ...       ...\n",
       "191  mitigate  document2  0.006645\n",
       "192  possible  document2  0.006645\n",
       "193      food  document2  0.006645\n",
       "194  scarcity  document2  0.006645\n",
       "300    report  document3  0.006645\n",
       "\n",
       "[903 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs = []\n",
    "\n",
    "# We'll caclulate the tf-idf value for every word across every document\n",
    "\n",
    "# Start by iterating over all the documents\n",
    "for doc, text in documents.items():\n",
    "    # We'll make a data frame that contains the tf for every word in every document\n",
    "    df = (pd.Series(text.split())\n",
    "          .value_counts()\n",
    "          .reset_index()\n",
    "          .set_axis(['word', 'raw_count'], axis=1)\n",
    "          .assign(tf=lambda df: df.raw_count / df.shape[0])\n",
    "          .drop(columns='raw_count')\n",
    "          .assign(doc=doc))\n",
    "    # Then add that data frame to our list\n",
    "    tfs.append(df)\n",
    "\n",
    "# We'll then concatenate all the tf values together.\n",
    "(pd.concat(tfs)\n",
    " # calculate the idf value for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # then use the if and idf values to calculate tf-idf \n",
    " .assign(tf_idf=lambda df: df.idf * df.tf)\n",
    " .drop(columns=['tf', 'idf'])\n",
    " .sort_values(by='tf_idf', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad1b3b50-4bd4-4cc2-9035-1ef6650f3115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>10</th>\n",
       "      <th>1000</th>\n",
       "      <th>100000</th>\n",
       "      <th>103</th>\n",
       "      <th>1066</th>\n",
       "      <th>11</th>\n",
       "      <th>1349</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>wednesday</th>\n",
       "      <th>west</th>\n",
       "      <th>white</th>\n",
       "      <th>withdrawn</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>worldwide</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>document1</th>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019934</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.006645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document2</th>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.019934</td>\n",
       "      <td>0.006645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document3</th>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019934</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.019934</td>\n",
       "      <td>0.013289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "word             03        04        10      1000    100000       103  \\\n",
       "doc                                                                     \n",
       "document1  0.006645  0.006645  0.006645  0.006645  0.013289  0.013289   \n",
       "document2  0.006645  0.006645  0.013289  0.006645  0.006645  0.006645   \n",
       "document3  0.013289  0.013289  0.006645  0.013289  0.006645  0.006645   \n",
       "\n",
       "word           1066        11      1349        14  ...  wednesday      west  \\\n",
       "doc                                                ...                        \n",
       "document1  0.006645  0.013289  0.013289  0.013289  ...   0.019934  0.006645   \n",
       "document2  0.013289  0.006645  0.006645  0.006645  ...   0.013289  0.006645   \n",
       "document3  0.006645  0.006645  0.006645  0.006645  ...   0.019934  0.013289   \n",
       "\n",
       "word          white  withdrawn      work    worker  worldwide     would  \\\n",
       "doc                                                                       \n",
       "document1  0.006645   0.013289  0.006645  0.006645   0.013289  0.006645   \n",
       "document2  0.013289   0.013289  0.006645  0.006645   0.006645  0.006645   \n",
       "document3  0.006645   0.026578  0.013289  0.013289   0.006645  0.013289   \n",
       "\n",
       "word           year      zone  \n",
       "doc                            \n",
       "document1  0.013289  0.006645  \n",
       "document2  0.019934  0.006645  \n",
       "document3  0.019934  0.013289  \n",
       "\n",
       "[3 rows x 301 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll then concatenate all the tf values together.\n",
    "(pd.concat(tfs)\n",
    " # calculate the idf value for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # then use the if and idf values to calculate tf-idf \n",
    " .assign(tf_idf=lambda df: df.idf * df.tf)\n",
    " .drop(columns=['tf', 'idf'])\n",
    " .sort_values(by='tf_idf', ascending=False)\n",
    " .pipe(lambda df: pd.crosstab(df.doc, df.word, values=df.tf_idf, aggfunc=lambda x: x))\n",
    " .fillna(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eb18d7-2f8d-42eb-aede-476be9ed032e",
   "metadata": {},
   "source": [
    "# Modeling Wiht scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2489a35-b7c3-422f-b418-bc125a325486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8eec9348-4bdd-4254-9f4f-65f14ed7bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf = TfidfVectorizer()\n",
    "# tfidfs = tfidf.fit_transform(documents.values())\n",
    "# tfidfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9770e307-f102-48c1-a47b-3a389e897faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(tfidfs.todense(), columns=tfidf.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e73d6987-70e1-4755-b16b-d186d46b6178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "id                                                         \n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = env.get_db_access(\"spam_db\")\n",
    "sql = \"SELECT * FROM spam\"\n",
    "\n",
    "df = pd.read_sql(sql, url, index_col=\"id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24ab3867-47f5-4016-9800-d8aa052f5b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457,), (1115,), (4457,), (1115,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = df.text\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "162fc558-bde1-48ee-bcdc-164b14263e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "873aac12-b08e-4793-b123-dfcd3e8693bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.51%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3857   109\n",
      "spam          2   489\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       1.00      0.82      0.90       598\n",
      "\n",
      "    accuracy                           0.98      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.98      0.98      0.97      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec4a7416-2ce8-4168-890d-830e889c84f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.04%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        963    30\n",
      "spam         3   119\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98       966\n",
      "        spam       0.98      0.80      0.88       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.97      0.90      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
